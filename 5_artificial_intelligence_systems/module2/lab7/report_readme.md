# *Лабораторная работа 4. Логистическая регрессия*
[Отчёт по лабораторной работе № 7](https://github.com/ITSamantha/artificial_intelligence_systems/blob/main/module2/lab7/readme.md)
## Введение
### Цель
Цель данной лабораторной работы заключается в реализации метода логистической регрессии "с нуля" без использования сторонних библиотек, кроме NumPy и Pandas. Мы будем использовать датасет о диабете для выполнения задачи классификации. 
### Задачи
- Датасет о диабете: [Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database)
- Загрузите выбранный датасет и выполните предварительную обработку данных.
- Разделите данные на обучающий и тестовый наборы в соотношении, которое вы считаете подходящим.
- Реализуйте логистическую регрессию "с нуля" без использования сторонних библиотек, кроме NumPy и Pandas. Ваша реализация логистической регрессии должна включать в себя:
    - Функцию для вычисления гипотезы (sigmoid function).
    - Функцию для вычисления функции потерь (log loss).
    - Метод обучения, который включает в себя градиентный спуск.
    - Возможность варьировать гиперпараметры, такие как коэффициент обучения (learning rate) и количество итераций.
1. Исследование гиперпараметров:
    - Проведите исследование влияния гиперпараметров на производительность модели. Варьируйте следующие гиперпараметры:
        - Коэффициент обучения (learning rate).
        - Количество итераций обучения.
        - Метод оптимизации (например, градиентный спуск или оптимизация Ньютона).
2. Оценка модели:
    - Для каждой комбинации гиперпараметров оцените производительность модели на тестовом наборе данных, используя метрики, такие как accuracy, precision, recall и F1-Score.

Сделайте выводы о том, какие значения гиперпараметров наилучшим образом работают для данного набора данных и задачи классификации. Обратите внимание на изменение производительности модели при варьировании гиперпараметров.
Ключевыми задачами в данной работе будут:
- Подготовка и предварительная обработка данных из датасета.
- Реализация метода логистической регрессии с использованием функций для вычисления гипотезы и функции потерь.
- Исследование влияния гиперпараметров на производительность модели.
- Оценка модели с использованием различных метрик.
  
## Описание метода
Логистическая регрессия - это статистический метод, используемый для анализа и моделирования отношений между зависимой бинарной переменной (обычно принимающей значения 0 или 1) и одной или несколькими независимыми переменными (предикторами). Её название "логистическая" происходит от функции, которую она использует для оценки вероятности классификации в зависимости от входных данных.
Назначение логистической регрессии:
- Классификация: Логистическая регрессия используется для предсказания принадлежности объекта к одному из двух классов (бинарная классификация). Например, оценка вероятности того, будет ли клиент банка погашать кредит или нет.
- Моделирование вероятности: Метод позволяет моделировать вероятности, что объект принадлежит к определенному классу. Это полезно, когда важно знать не только принадлежность к классу, но и уверенность в этом принятии решения.
Принцип работы логистической регрессии:
1. Сбор данных: Собираются данные, включая зависимую переменную (целевую) и одну или несколько независимых переменных (предикторов).
2. Подготовка данных: Данные должны быть очищены, преобразованы и масштабированы при необходимости.
3. Обучение модели: Модель обучается на тренировочных данных путем нахождения оптимальных весов (коэффициентов) для каждого предиктора с использованием метода максимального правдоподобия.
4. Прогнозирование: После обучения модель может быть использована для прогнозирования вероятности принадлежности объектов к классу на основе их характеристик.
5. Оценка производительности: Модель оценивается с использованием метрик, таких как точность, полнота, F1-мера, ROC-кривая и AUC, чтобы оценить ее качество и способность к обобщению на новые данные.
Логистическая регрессия использует логистическую функцию (сигмоид) для оценки вероятности, что объект принадлежит к классу.

## Псевдокод метода

```
# Инициализация модели
Инициализировать веса модели (weights)

# Задание гиперпараметров
скорость_обучения = 0.01  # Скорость обучения
количество_итераций = 1000  # Количество итераций обучения

# Цикл для обучения
Для каждой итерации в интервале [1, количество_итераций]:
    # Вычисление линейной комбинации
    z = Вычислить линейную комбинацию (признаки, weights)
    
    # Применение сигмоидной функции
    вероятности = Применить сигмоидную функцию (z)
    
    # Вычисление градиента
    градиент = Вычислить градиент (признаки, метки, вероятности)
    
    # Обновление весов
    Обновить веса (weights, градиент, скорость_обучения)

# Получение прогнозов
новые_данные = [признак_1, признак_2, ..., признак_n]
прогноз_вероятности = Получить_прогноз (новые_данные, weights)
```
## Результаты выполнения 
По результатам выполнения лабораторной работы, была проведена реализация логистической регрессии "с нуля" без использования сторонних библиотек, за исключением NumPy и Pandas. Эта реализация включает в себя функции для вычисления гипотезы (сигмоидной функции), функции для вычисления функции потерь (логистическая функция потерь), а также метод обучения, который использует градиентный спуск. Также была возможность варьировать гиперпараметры, такие как коэффициент обучения (learning rate) и количество итераций.

Датасет о диабете был загружен и предварительно обработан. Данные были разделены на обучающий и тестовый наборы. После этого была проведена реализация логистической регрессии и исследование влияния гиперпараметров на производительность модели. Были варьированы параметры, такие как коэффициент обучения (learning rate), количество итераций обучения и метод оптимизации (градиентный спуск или оптимизация Ньютона).

Для каждой комбинации гиперпараметров была оценена производительность модели на тестовом наборе данных с использованием метрик, таких как accuracy, precision, recall и F1-Score.

В результате исследования гиперпараметров были выявлены лучшие параметры модели. Метод градиентного спуска показал следующие лучшие параметры:
```
1)
Количество итераций: 1000
Learning rate: 0.5
Accuracy: 0.824
Метод: Градиентного спуска
```
Метод оптимизации Ньютона показал следующие лучшие параметры:
```
2)
Количество итераций: 500
Learning rate: не применяется
Accuracy: 0.805
Метод: Оптимизации Ньютона
```
В целом, результаты показали, что метод градиентного спуска с подходящими гиперпараметрами дал лучшие результаты в данной задаче классификации на тестовом наборе данных. Также было отмечено, что метод оптимизации Ньютона дал стабильные результаты, но несколько менее точные по сравнению с методом градиентного спуска.
Кроме того, была проведена сравнительная оценка реализованной модели с моделью, реализованной с использованием библиотеки sklearn, и реализованная модель показала лучшую точность (accuracy).

### Анализ данных и визуализация
В начале лабораторной работы был произведен анализ данных и визуализация. Для анализа использовался датасет о диабете, и задачей было понять структуру данных и характеристики признаков. Анализ данных включал в себя следующие шаги:
- Загрузка данных: Датасет был загружен из источника данных (в данном случае, предоставленного датасета о диабете с Kaggle).
- Описание данных: Были получены статистические показатели о данных, такие как среднее значение, стандартное отклонение, минимальное и максимальное значения, что позволило понять характер данных.
- Визуализация данных: Используя библиотеки Seaborn и Matplotlib, данные были визуализированы в виде графиков, гистограмм, и диаграмм рассеяния. Это позволило более наглядно представить распределение признаков и их взаимосвязи.
Анализ данных и визуализация помогли понять, какие признаки важны для задачи классификации и какие могут быть коррелированы друг с другом.

- Описание датасета:

  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/153adc0f-918c-448d-8f07-0de9a73db557)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/cdc0044b-fd2b-4bd5-9d66-b939c4118dc3)

- Описание статистики атрибутов:

  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/b7c4892b-d139-414a-86c7-c92f46934c9f)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/0ebea341-ec1d-4cd1-9a84-c6c0d6e7aca1)

- Визуализация данных
  
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/9046f47b-c6a9-4964-b0e8-b34868425773)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/42be7981-d0fa-4fef-9776-86a402b41920)

### Предварительная обработка данных

Предварительная обработка данных включала в себя следующие этапы:
1. Обработка отсутствующих значений: Проверка наличия отсутствующих значений в данных и их обработка, например, путем удаления строк с отсутствующими значениями или заполнения их средними значениями.
2. Нормализация данных: Приведение данных к общему масштабу, чтобы уровни различных признаков были сопоставимы.
3. Кодирование категориальных признаков: Если в данных были категориальные признаки, они могли быть закодированы в числовом формате для использования в модели.

Предварительная обработка данных была важным этапом, чтобы подготовить данные для обучения модели логистической регрессии.

- Предварительная обработка данных

  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/a8142168-5c6b-4e6a-bcfa-b797491fb140)

### Построение модели
Построение модели логистической регрессии было выполнено в несколько этапов:
1. Реализация гипотезы: Была реализована функция для вычисления гипотезы, использующей сигмоидную функцию.
2. Реализация функции потерь: Была реализована функция для вычисления функции потерь, используя логистическую функцию потерь.
3. Обучение модели: Модель была обучена на обучающем наборе данных с использованием градиентного спуска или оптимизации Ньютона, в зависимости от выбора пользователя. Обучение включало в себя итерации, в ходе которых веса модели обновлялись с целью минимизации функции потерь.
4. Оценка производительности: После обучения модели, ее производительность была оценена на тестовом наборе данных с использованием метрик, таких как accuracy, precision, recall и F1-Score.

- Перебор возможных параметров для выявления лучших:
  
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/6ad33ffa-6364-42b2-a325-5e3f84296f29)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/208bad0d-b2d3-4b31-b8a7-47b3cf0da9de)

- Лучшие параметры:

  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/ba6ff719-f743-4afe-b924-50b9411df60d)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/d7edbace-7d54-4529-9f91-96f09a19528c)

  
### Оценка производительности
Для оценки производительности модели были использованы следующие метрики:
- Accuracy: Определяет, насколько точно модель классифицирует данные.
- Precision: Оценивает долю верно предсказанных положительных классов относительно всех предсказанных положительных классов.
- Recall: Оценивает долю верно предсказанных положительных классов относительно всех истинных положительных классов.
- F1-Score: Гармоническое среднее precision и recall, позволяет оценить баланс между ними.

Оценка производительности позволила определить, насколько хорошо модель работает в задаче классификации диабета.

### Особенности
- Получение статистики реализовано с помощью библиотеки Pandas. Визуализация данных реализована с помощью библиотек Seaborn и matplotlib.pyplot. Кодирование категориальных признаков в данном случае не нужно, нормировка реализована.
- Логистическая регрессия реализована нескольими функциями. Одна из наиболее важных - функция для вычисления гипотезы. Также реализованы функции нахождения функции потерь.
- Обучение модели может выполняться двумя методами: обучение с градиентным спуском(с learning rate) или оптимизацией Ньютона(без learning rate). 
- У пользователя есть возможность варьировать гиперпараметры, такие как коэффициент обучения (learning rate) и количество итераций.
- Реализованы функции для нахождения метрик: accuracy, precision, recall и F1-Score.
- Для нахождения наилучших параметров было решено запустить цикл с переборами всех параметров, лучшие показатели были выявлены в ходе работы программы.
- Написана также версия с использованием библиотеки sklearn.
Данная реализация логистической регрессии должна включать в себя:
    - Функцию для вычисления гипотезы (sigmoid function).
    - Функцию для вычисления функции потерь (log loss).
    - Метод обучения, который включает в себя градиентный спуск.
    - Возможность варьировать гиперпараметры, такие как коэффициент обучения (learning rate) и количество итераций.

### Лучшие параметры реализованной библиотеки

  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/9b2e5384-eadf-4b0d-bc0a-a19c74823bc7)
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/ba6ff719-f743-4afe-b924-50b9411df60d)

### Лучшие параметры sklearn
  ![image](https://github.com/ITSamantha/Artificial_Intelligence_Systems/assets/100091168/efb8e5e7-cb82-4b2b-950c-e78cd01ed8cc)

**Лучшими показателями для данного датасета оказались (метод Градиентного спуска):**    
- Количество итераций: 1000                                                                
- Learning rate: 0.5                                                                       
- Accurancy: 0.824                                                                         
- Метод: Градиентного спуска                                                               

**Лучшими показателями для данного датасета оказались (метод Ньютона):**
- Количество итераций: 500
- Learning rate: -
- Accurancy: 0.805
- Метод: Оптимизации Ньютона
  
## Примеры использования метода
Логистическая регрессия является одним из простых и эффективных методов классификации, особенно в случаях, когда зависимость между признаками и целевой переменной линейна.
Метод логистической регрессии может быть полезен во множестве ситуаций, где необходима бинарная классификация (разделение данных на два класса) или многоклассовая классификация (разделение данных на более чем два класса). Вот некоторые примеры ситуаций, когда метод логистической регрессии может быть полезен:
- Медицинская диагностика: Логистическая регрессия может использоваться для диагностики различных заболеваний, таких как диабет, рак и сердечные заболевания, на основе медицинских признаков пациента.
- Кредитный скоринг: Банки и финансовые учреждения могут применять логистическую регрессию для оценки кредитоспособности заявителей на основе их финансовых данных, чтобы принять решение о выдаче кредита.
- Прогнозирование оттока клиентов: Компании могут использовать логистическую регрессию для определения вероятности оттока клиентов и разработки стратегий для их удержания.
- Маркетинг и реклама: Логистическая регрессия может помочь в прогнозировании вероятности того, что клиент совершит покупку или выполнит конверсию после просмотра рекламы.
- Спам-фильтры: Для классификации электронных сообщений на спам и не-спам логистическая регрессия может быть эффективным методом.
- Предсказание вероятности событий: Логистическая регрессия может использоваться для прогнозирования вероятности различных событий, таких как победа или поражение в спорте, успех или неуспех в бизнесе и другие.

Почему выбрана логистическая регрессия:
- Простота и интерпретируемость: Логистическая регрессия - это относительно простой метод, который легко интерпретировать. Модель предоставляет вероятности принадлежности к классам, и вы можете понять, какие признаки влияют на принятие решения.
- Эффективность: Логистическая регрессия обладает хорошей производительностью на больших наборах данных, и обучение модели может быть выполнено быстро.
- Подходит для линейно разделимых данных: В случаях, когда данные можно разделить линейной границей между классами, логистическая регрессия работает хорошо.
- Модификации для многоклассовой классификации: Логистическая регрессия может быть расширена на задачи многоклассовой классификации с использованием методов, таких как "One-vs-Rest" или "Softmax".
Логистическая регрессия представляет собой мощный инструмент для решения разнообразных задач классификации, и ее простота и эффективность делают ее популярным выбором в многих областях.
